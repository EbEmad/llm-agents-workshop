{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d461feb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0471ecb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'finish_reason': 'stop',\n",
      " 'id': 'chatcmpl-749',\n",
      " 'logprobs': None,\n",
      " 'model_name': 'qwen2.5:7b',\n",
      " 'model_provider': 'openai',\n",
      " 'system_fingerprint': 'fp_ollama',\n",
      " 'token_usage': {'completion_tokens': 184,\n",
      "                 'completion_tokens_details': None,\n",
      "                 'prompt_tokens': 35,\n",
      "                 'prompt_tokens_details': None,\n",
      "                 'total_tokens': 219}}\n",
      "(\"Of course! I'd be happy to assist you with a wide range of topics and tasks. \"\n",
      " 'Here are some ways I can help:\\n'\n",
      " '\\n'\n",
      " '1. **Information Retrieval**: Look up information on various subjects, '\n",
      " 'including science, history, technology, and more.\\n'\n",
      " '2. **Writing Assistance**: Help with writing essays, articles, emails, or '\n",
      " 'any other type of text. I can also provide feedback on your drafts.\\n'\n",
      " '3. **Language Translation**: Translate text from one language to another.\\n'\n",
      " '4. **Learning and Education**: Provide explanations, definitions, and '\n",
      " 'examples for educational purposes.\\n'\n",
      " '5. **Problem Solving**: Assist with math problems, programming questions, '\n",
      " 'logical puzzles, and more.\\n'\n",
      " '6. **Research Support**: Help find relevant sources or articles for your '\n",
      " 'research projects.\\n'\n",
      " '7. **Personal Advice**: Offer advice on career choices, personal '\n",
      " 'development, and other life-related topics.\\n'\n",
      " '\\n'\n",
      " 'Please let me know what specific help you need!')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from pprint import pprint\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"qwen2.5:7b\",\n",
    "    temperature=0,\n",
    "    api_key=\"ollama\", # Required for ChatOpenAI, can be anything for Ollama\n",
    "    base_url=\"https://milo-uncostly-overmilitaristically.ngrok-free.dev/v1\"\n",
    ")\n",
    "response = model.invoke(\"how can you help me?\")\n",
    "pprint(response.response_metadata)\n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30e18346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello! How can I help you today?' additional_kwargs={} response_metadata={'id': 'msg_01KoKoCALGiNrdRF9eUruMPN', 'model': 'claude-sonnet-4-5-20250929', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 8, 'output_tokens': 12, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-5-20250929', 'model_provider': 'anthropic'} id='lc_run--019b89ea-c7b5-75d2-92ec-76f545bfdab3-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 8, 'output_tokens': 12, 'total_tokens': 20, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "model = ChatAnthropic(model=\"claude-sonnet-4-5-20250929\")\n",
    "response = model.invoke(\"hi\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9440050e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a1966cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'msg_01KoKoCALGiNrdRF9eUruMPN',\n",
      " 'model': 'claude-sonnet-4-5-20250929',\n",
      " 'model_name': 'claude-sonnet-4-5-20250929',\n",
      " 'model_provider': 'anthropic',\n",
      " 'stop_reason': 'end_turn',\n",
      " 'stop_sequence': None,\n",
      " 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0,\n",
      "                              'ephemeral_5m_input_tokens': 0},\n",
      "           'cache_creation_input_tokens': 0,\n",
      "           'cache_read_input_tokens': 0,\n",
      "           'input_tokens': 8,\n",
      "           'output_tokens': 12,\n",
      "           'server_tool_use': None,\n",
      "           'service_tier': 'standard'}}\n"
     ]
    }
   ],
   "source": [
    "pprint(response.response_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fee4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Hello! How can I assist you today?'\n",
      "{'created_at': '2026-01-17T15:02:47.951867523Z',\n",
      " 'done': True,\n",
      " 'done_reason': 'stop',\n",
      " 'eval_count': 10,\n",
      " 'eval_duration': 277598993,\n",
      " 'load_duration': 152745529,\n",
      " 'logprobs': None,\n",
      " 'model': 'qwen2.5:7b',\n",
      " 'model_name': 'qwen2.5:7b',\n",
      " 'model_provider': 'ollama',\n",
      " 'prompt_eval_count': 30,\n",
      " 'prompt_eval_duration': 32442601,\n",
      " 'total_duration': 500035948}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model #general function\n",
    "from pprint import pprint\n",
    "\n",
    "# Specify model_provider=\"ollama\"\n",
    "model = init_chat_model(\n",
    "    \"qwen2.5:7b\", \n",
    "    model_provider=\"ollama\", \n",
    "    base_url=\"https://milo-uncostly-overmilitaristically.ngrok-free.dev\" # Optional: only if using your ngrok link\n",
    ")\n",
    "\n",
    "response = model.invoke(\"hi\")\n",
    "pprint(response.content)\n",
    "pprint(response.response_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3ecb31",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"openai:gpt-4o\")    \n",
    "response = model.invoke(\"hello!\")\n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33caec62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'finish_reason': 'stop',\n",
      " 'id': 'chatcmpl-CuLeHpiG9IuMZwjrjIIFK6ErcOFTY',\n",
      " 'logprobs': None,\n",
      " 'model_name': 'gpt-4o-2024-08-06',\n",
      " 'model_provider': 'openai',\n",
      " 'service_tier': 'default',\n",
      " 'system_fingerprint': 'fp_deacdd5f6f',\n",
      " 'token_usage': {'completion_tokens': 9,\n",
      "                 'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
      "                                               'audio_tokens': 0,\n",
      "                                               'reasoning_tokens': 0,\n",
      "                                               'rejected_prediction_tokens': 0},\n",
      "                 'prompt_tokens': 9,\n",
      "                 'prompt_tokens_details': {'audio_tokens': 0,\n",
      "                                           'cached_tokens': 0},\n",
      "                 'total_tokens': 18}}\n"
     ]
    }
   ],
   "source": [
    "pprint(response.response_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b74d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Default: OpenAI\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# OpenRouter (uses your OpenRouter API key)\n",
    "model = ChatOpenAI(\n",
    "    model=\"anthropic/claude-3-sonnet-20240229\",  # Non-OpenAI model via OpenRouter\n",
    "    api_key=\"987\",\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    ")\n",
    "\n",
    "# Local vLLM server\n",
    "model = ChatOpenAI(\n",
    "    model=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    api_key=\"987\",  # Dummy key for local\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97c1f247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='Hi — how can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 146, 'prompt_tokens': 7, 'total_tokens': 153, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 128, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CuNhE6RPU8Bj8GjNsgK4pWZEiMuIB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b8a65-e158-7fb1-b76b-5baf48b813d8-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 7, 'output_tokens': 146, 'total_tokens': 153, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 128}})\n"
     ]
    }
   ],
   "source": [
    "# invoke the model\n",
    "model = ChatOpenAI(model=\"gpt-5-mini\")\n",
    "response = model.invoke(\"hi\")\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d385af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of* course*!* I*'d* be* happy* to* assist* you* with* a* wide* range* of* topics* and* tasks*.* Here* are* some* ways* I* can* help*:\n",
      "\n",
      "*1*.* ***Information* Retrie*val***:* Look* up* information* on* various* subjects*,* including* science*,* history*,* technology*,* and* more*.\n",
      "*2*.* ***Writing* Assistance***:* Help* with* writing* essays*,* articles*,* emails*,* or* any* other* type* of* text*.* I* can* also* provide* feedback* on* your* drafts*.\n",
      "*3*.* ***Language* Translation***:* Translate* text* from* one* language* to* another*.\n",
      "*4*.* ***Learning* and* Education***:* Provide* explanations*,* definitions*,* and* examples* for* educational* purposes*.\n",
      "*5*.* ***Problem* Sol*ving***:* Assist* with* math* problems*,* programming* questions*,* logical* puzzles*,* and* more*.\n",
      "*6*.* ***Research* Support***:* Help* find* relevant* sources* or* articles* for* your* research* projects*.\n",
      "*7*.* ***Personal* Advice***:* Offer* advice* on* career* choices*,* personal* development*,* and* other* life*-related* topics*.\n",
      "\n",
      "*Please* let* me* know* what* specific* help* you* need*!***"
     ]
    }
   ],
   "source": [
    "for chunk in model.stream(\"how can you help me?\"):\n",
    "    print(chunk.text, end=\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4592ae3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! I'd be happy to assist you with a wide range of topics and tasks. Here are some ways I can help:\n",
      "\n",
      "1. **Information Retrieval**: Look up information on various subjects, including science, history, technology, and more.\n",
      "2. **Writing Assistance**: Help with writing essays, articles, emails, or any other type of text. I can also provide feedback on your drafts.\n",
      "3. **Language Translation**: Translate text from one language to another.\n",
      "4. **Learning and Education**: Provide explanations, definitions, and examples for educational purposes.\n",
      "5. **Problem Solving**: Assist with math problems, programming questions, logical puzzles, and more.\n",
      "6. **Research Support**: Help find relevant sources or articles for your research projects.\n",
      "7. **Personal Advice**: Offer advice on career choices, personal development, and other life-related topics.\n",
      "\n",
      "Please let me know what specific help you need!"
     ]
    }
   ],
   "source": [
    "for chunk in model.stream(\"how can you help me?\"):\n",
    "    print(chunk.text, end=\"\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e096f9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'text', 'text': \"I'm an AI model continuously maintained and updated by Alibaba Cloud, and I don't have specific training dates like a machine learning model would. My knowledge and responses are regularly refreshed to keep up with the latest information available up to my last update. For the most accurate and up-to-date information, please refer to reliable sources or ask about more recent topics directly.\"}]\n"
     ]
    }
   ],
   "source": [
    "full = None  \n",
    "for chunk in model.stream(\"what is the last date you trained\"):\n",
    "    full = chunk if full is None else full + chunk # merges chunks into one AIMessage \n",
    "print(full.content_blocks) # lazily parses into unified blocks: [{\"type\": \"text\", \"text\": \"Hello...\"}].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e717498a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "أنا Qwen، وهو نموذج لغة كبير تم إنشاؤه بواسطة شركة علي بابا للنube. أنا هنا للمساعدة في الإجابة على أسئلتك ومساعدتك في مجموعة متنوعة من المهام والنقاشات. كيف يمكنني المساعدة اليوم؟\n",
      "**************************************************\n",
      "الوصول إلى الفضاء يتطلب معرفة متخصصة وتجهيزات عالية التكنولوجيا، وهو أمر يقتصر عادة على وكالات الفضاء والشركات الخاصة المتخصصة. إذا كنت ترغب في الاطلاع على الفضاء أو دراسته، يمكنك اتباع الخطوات التالية:\n",
      "\n",
      "1. التعليم: حصل على تعليم جيد في العلوم، خاصة الفيزياء والكيمياء والرياضيات.\n",
      "\n",
      "2. البحث العلمي: شارك في برامج البحث العلمي المتعلقة بالفضاء.\n",
      "\n",
      "3. التطوع أو العمل في وكالة فضاء: يمكنك الانضمام إلى وكالات الفضاء مثل وكالة ناسا الأمريكية أو وكالة الفضاء الأوروبية أو وكالة الفضاء الروسية (روسكوسموس).\n",
      "\n",
      "4. التعليم والتدريب: قد تحتاج إلى تدريب خاص وتعليم متقدم في مجالات مثل الهندسة الفضائية.\n",
      "\n",
      "5. البحوث الخاصة: إذا كنت ترغب في العمل بشكل مستقل، يمكنك البحث عن فرص للعمل مع شركات خاصة تعمل في قطاع الفضاء.\n",
      "\n",
      "6. زيارة المواقع التعليمية والترفيهية: هناك العديد من المتاحف والمراكز العلمية التي تعرض معلومات قيمة حول الفضاء.\n",
      "\n",
      "7. القراءة والتعرف على تاريخ الفضاء: تعلم عن الرحلات الفضائية السابقة وابدأ في فهم كيفية الوصول إلى الفضاء.\n",
      "\n",
      "تذكر أن الوصول الفعلي إلى الفضاء يتطلب استثمارات كبيرة ومعرفة متخصصة، لكن يمكنك بدء رحلتك من خلال الاطلاع والمعرفة.\n",
      "**************************************************\n",
      "ذكاء اصطناعي (Artificial Intelligence، AI) هو مجال في علوم الحاسوب يهدف إلى إنشاء برامج ونماذج تتيح للحواسيب والأنظمة الآلية القيام بأنواع معينة من المهام التي تتطلب ذكاءً بشريًا. هذه المهام قد تشمل التعلم الذاتي، الفهم اللغوي، حل المشكلات، التعرف على الأنماط، والتواصل البشري.\n",
      "\n",
      "الذكاء الاصطناعي يمكن أن يساعد في حل مجموعة متنوعة من المشاكل والتحديات في العديد من المجالات مثل الطب، التعليم، الصناعة، النقل، وغيرها.\n",
      "**************************************************\n",
      "CPU times: user 19.7 ms, sys: 1.38 ms, total: 21.1 ms\n",
      "Wall time: 18.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "responses = model.batch([\n",
    "    \"من انت؟\",\n",
    "    \"كيف اطلع الفضاء\",\n",
    "    \" يعني ايه ذكاء اصطناعي؟\"\n",
    "])\n",
    "for response in responses:\n",
    "    print(response.content)\n",
    "    print('*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3843634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, AIMessage(content='أنا Qwen، وهو نموذج لغة كبير تم إنشاؤه بواسطة شركة علي بابا للنube. أنا هنا للمساعدة في الإجابة على أسئلتك ومساعدتك في مجموعة متنوعة من المهام والنقاشات. كيف يمكنني المساعدة اليوم؟', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 33, 'total_tokens': 101, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen2.5:7b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-249', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bd0f5-0ec0-7a91-8230-3ab889ddd43c-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 33, 'output_tokens': 68, 'total_tokens': 101, 'input_token_details': {}, 'output_token_details': {}}))\n",
      "**************************************************\n",
      "(1, AIMessage(content='الوصول إلى الفضاء يتطلب معرفة متخصصة وتجهيزات عالية التكنولوجيا، وهو أمر يقتصر عادة على وكالات الفضاء والشركات الخاصة المتخصصة. إذا كنت ترغب في الاطلاع على الفضاء أو دراسته، يمكنك اتباع الخطوات التالية:\\n\\n1. التعليم: حصل على تعليم جيد في العلوم، خاصة الفيزياء والكيمياء والرياضيات.\\n\\n2. البحث العلمي: شارك في برامج البحث العلمي المتعلقة بالفضاء.\\n\\n3. التطوع أو العمل في وكالة فضاء: يمكنك الانضمام إلى وكالات الفضاء مثل وكالة ناسا الأمريكية أو وكالة الفضاء الأوروبية أو وكالة الفضاء الروسية (روسكوسموس).\\n\\n4. التعليم والتدريب: قد تحتاج إلى تدريب خاص وتعليم متقدم في مجالات مثل الهندسة الفضائية.\\n\\n5. البحوث الخاصة: إذا كنت ترغب في العمل بشكل مستقل، يمكنك البحث عن فرص للعمل مع شركات فضاء خاصة أو حتى بدء مشروعك الخاص.\\n\\n6. زيارة المواقع التعليمية والترفيهية: هناك العديد من المتاحف والمراكز العلمية التي تعرض معلومات قيمة حول الفضاء.\\n\\n7. القراءة والتعرف على تاريخ الفضاء: قم بقراءة الكتب والأبحاث المتعلقة بالفضاء لفهم ما تم تحقيقه حتى الآن وما يمكن أن يتم في المستقبل.\\n\\nتذكر أنه الوصول الفعلي إلى الفضاء يتطلب استثمارات ضخمة وخبرات متخصصة، لكن يمكنك بدء رحلتك نحو فهم الفضاء من خلال هذه الخطوات.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 353, 'prompt_tokens': 34, 'total_tokens': 387, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen2.5:7b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-315', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bd0f5-0ec1-7f71-95d1-ca7a330ffade-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 34, 'output_tokens': 353, 'total_tokens': 387, 'input_token_details': {}, 'output_token_details': {}}))\n",
      "**************************************************\n",
      "(2, AIMessage(content='ذكاء اصطناعي (Artificial Intelligence، AI) هو مجال في علوم الحاسوب يهدف إلى إنشاء برامج ونماذج تتيح للحواسيب والأنظمة الآلية القيام بأنواع معينة من المهام التي تتطلب ذكاءً بشريًا. هذه المهام قد تشمل التعلم الذاتي، الفهم اللغوي، حل المشكلات، التعرف على الأنماط، والتواصل البشري.\\n\\nالذكاء الاصطناعي يمكن أن يساعد في حل مجموعة متنوعة من المشاكل والتحديات في العديد من المجالات مثل الطب، التعليم، الصناعة، النقل، وغيرها.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 148, 'prompt_tokens': 41, 'total_tokens': 189, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen2.5:7b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-159', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bd0f5-0ec4-7a11-8700-e10439a1dce0-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 41, 'output_tokens': 148, 'total_tokens': 189, 'input_token_details': {}, 'output_token_details': {}}))\n",
      "**************************************************\n",
      "CPU times: user 20.9 ms, sys: 3.71 ms, total: 24.6 ms\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "responses = model.batch_as_completed([\n",
    "    \"من انت؟\",\n",
    "    \"كيف اطلع الفضاء\",\n",
    "    \" يعني ايه ذكاء اصطناعي؟\"\n",
    "])\n",
    "for response in responses:\n",
    "    print(response)\n",
    "    print('*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd34f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    model=\"qwen2.5:7b\",\n",
    "    temperature=0,\n",
    "    api_key=\"ollama\", # Required for ChatOpenAI, can be anything for Ollama\n",
    "    base_url=\"https://milo-uncostly-overmilitaristically.ngrok-free.dev/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edca1101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get the weather at a location.\"\"\"\n",
    "    return f\"It's sunny in {location} at morning and cold at night.\"\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"qwen2.5:7b\",\n",
    "    temperature=0,\n",
    "    api_key=\"ollama\", # Required for ChatOpenAI, can be anything for Ollama\n",
    "    base_url=\"https://milo-uncostly-overmilitaristically.ngrok-free.dev/v1\")\n",
    "\n",
    "\n",
    "model_with_tools = model.bind_tools([get_weather])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d89a4c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: get_weather\n",
      "Args: {'location': 'Egypt'}\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke(\"What's the weather like in Egypt?\")\n",
    "\n",
    "for tool_call in response.tool_calls:\n",
    "    # View tool calls made by the model\n",
    "    print(f\"Tool: {tool_call['name']}\")\n",
    "    print(f\"Args: {tool_call['args']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03366912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 153, 'total_tokens': 173, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen2.5:7b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-338', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--019bd0f7-fcff-7301-a4c9-9b3614a194cd-0' tool_calls=[{'name': 'get_weather', 'args': {'location': 'Egypt'}, 'id': 'call_van1bby4', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 153, 'output_tokens': 20, 'total_tokens': 173, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0729be34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Bind (potentially multiple) tools to the model\n",
    "model_with_tools = model.bind_tools([get_weather])\n",
    "\n",
    "# Step 1: Model generates tool calls\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather Egypt?\"}]\n",
    "ai_msg = model_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "# Step 2: Execute tools and collect results\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    # Execute the tool with the generated arguments\n",
    "    tool_result = get_weather.invoke(tool_call)\n",
    "    messages.append(tool_result)\n",
    "\n",
    "# Step 3: Pass results back to model for final response\n",
    "final_response = model_with_tools.invoke(messages)\n",
    "print(final_response.text)\n",
    "\n",
    "# streaming\n",
    "# for chunk in model_with_tools.stream(messages):\n",
    "#     print(chunk.text, end = \"\", flush=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e4fde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
